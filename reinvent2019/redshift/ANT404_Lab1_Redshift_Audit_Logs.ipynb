{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANT404 Lab #1 - Query Redshift Audit Logs\n",
    "\n",
    "In this lab you will use Redshift Spectrum to query Redshift Audit logs. A bucket of example logs has been shared with your test account. \n",
    "\n",
    "\n",
    "### Background on Redshift Audit Logs\n",
    "Audit logging is not enabled by default in Amazon Redshift. When you enable logging on your cluster, Amazon Redshift creates and uploads logs to Amazon S3 that capture data from the creation of the cluster to the present time. Each logging update is a continuation of the information that was already logged. \n",
    "\n",
    "Once enabled, Amazon Redshift logs information in the following log files:\n",
    "* **Connection log** : authentication attempts, and connections and disconnections.\n",
    "* **User log** : information about changes to database user definitions.  [Not used in this lab]\n",
    "* **User activity log** : logs each query before it is run on the database.\n",
    "\n",
    "Redshift Audit logs use multiple formats:\n",
    "* **Connection log** files use a pipe delimited flat file format. \n",
    "* **User activity log** files do not have explicit delimiters, you will use a regular expression to define the fields. \n",
    "\n",
    "\n",
    "\n",
    "## 1. Check for credentials file\n",
    "Check for the credentials created in the `START_HERE` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat ant404-lab.creds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set local variables from credentials file\n",
    "Run this `cell` to import the credentials created in `START_HERE` notebook into this notebook. Later cells rely on these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson\n",
    "with open(\"ant404-lab.creds\") as fh:\n",
    "    creds = simplejson.loads(fh.read())\n",
    "username=creds[\"user_name\"]\n",
    "password=creds[\"password\"]\n",
    "host_name=creds[\"host_name\"]\n",
    "port_num=creds[\"port_num\"]\n",
    "db_name=creds[\"db_name\"]\n",
    "\n",
    "# Example Account, Region, and Cluster values for this lab\n",
    "log_account=123456789101\n",
    "region=\"us-east-1\"\n",
    "cluster_name=\"reporting-cluster\"\n",
    "\n",
    "# Default date values used to get sample files\n",
    "audit_year=2019\n",
    "audit_month=11\n",
    "audit_day=10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set `env` shell variables with Audit log location elements\n",
    "Run the `cell` to set these variables in the local shell. Do not quote the `%set_env` variable strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env username={username}\n",
    "%set_env log_account={log_account}\n",
    "\n",
    "# Default date value used to get sample files\n",
    "%set_env audit_date={audit_year}-{audit_month}-{audit_day}\n",
    "%set_env audit_date_path=year={audit_year}/month={audit_month}/day={audit_day}\n",
    "\n",
    "# S3 bucket for logs \n",
    "%set_env log_bucket=redshift-managed-spectrum-datasets-{region}\n",
    "\n",
    "# S3 prefix path for logs\n",
    "%set_env audit_prefix=dataset=auditlog/region={region}\n",
    "\n",
    "# Log file name excluding date\n",
    "%set_env audit_file={log_account}_redshift_{region}_{cluster_name}_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. List the Audit Logs of each type\n",
    "Run the following cells to count the Audit Logs of each type and list the first.\n",
    "\n",
    "Notice that all Audit logs are in one S3 prefix, only the file name tells us the log type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "audit_log_full_prefix=$log_bucket/$audit_prefix/$audit_date_path/$audit_file\n",
    "\n",
    "## Count and List the logs with the AWS CLI\n",
    "echo \"ConnectionLog files: \"\n",
    "echo \"s3://$audit_log_full_prefix\"\n",
    "echo \"-----------------------------\"\n",
    "aws s3 ls s3://$audit_log_full_prefix\"connectionlog_\" --summarize\n",
    "\n",
    "echo \"\"; echo \"UserActivityLog files: \"\n",
    "echo \"s3://$audit_log_full_prefix\"\n",
    "echo \"-----------------------------\"\n",
    "aws s3 ls s3://$audit_log_full_prefix\"useractivitylog_\" --summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download and preview a `ConnectionLog` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "file=\"${audit_file}connectionlog_${audit_date}T00:27\"\n",
    "# Download with the AWS CLI\n",
    "aws s3 cp s3://$log_bucket/$audit_prefix/$audit_date_path/${file}.gz ${file}.gz\n",
    "gzip -df ${file}.gz  # Unzip\n",
    "head -15 ${file}     # Print 15 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create manifests to refer to the separate Audit log file types\n",
    "The `LOCATION` parameter for a Redshift Spectrum external table must refer to a prefix \"folder\" ending with a slash `/`. When different file types are in the same prefix you must use a manifest file to tell Redshift which files are part of the table.\n",
    "\n",
    "The 3 types of Audit Logs are written to the same prefix. Here you will use the AWS CLI to create 1 manifest per day for each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Make a folder for the manifests\n",
    "if [ ! -d manifests ]; then mkdir -p manifests; fi\n",
    "# This function does the work\n",
    "# > List the files in each prefix\n",
    "# > Convert them into the manifest JSON \n",
    "# > Write them to the local folder\n",
    "create_manifest(){ \n",
    "  aws s3api list-objects-v2 --bucket $1 --prefix ${2}/${3}/${4}${5} \\\n",
    "      --output json --query 'Contents[].{Key: Key, Size: Size}' | \\\n",
    "    jq '{entries: [ .[] | ({url: (\"s3://'${1}'/\" + .Key), meta: {content_length: .Size}})]}' \\\n",
    "    > manifests/${4}${5}_${6}.manifest\n",
    "}\n",
    "# Register the function\n",
    "export -f create_manifest \n",
    "declare -a log_types=(\"connectionlog\" \"useractivitylog\")\n",
    "for type in \"${log_types[@]}\"; do\n",
    "# Run this loop for all the days in the data\n",
    "    for day in $(seq -w 1 22); do\n",
    "        manifest_date=\"2019_11_$day\"\n",
    "        audit_date_path=\"year=2019/month=11/day=$day\"\n",
    "# Echo the arguments for each day\n",
    "        echo $log_bucket $audit_prefix $audit_date_path $audit_file $type $manifest_date\n",
    "    done\n",
    "# Xargs runs the function in parallel to speed things up\n",
    "done | xargs -n 6 -P 11 -I {} bash -c 'create_manifest $@' _ {}\n",
    "ls manifests/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  Upload the manifests to an S3 bucket\n",
    "A bucket has already been created in your lab account for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Upload all manifests with the AWS CLI\n",
    "aws s3 cp ./manifests/ s3://ant404-lab-86feeb76/manifests/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Connect to your Redshift cluster\n",
    "\n",
    "You will use the `sqlalchemy` and `ipython-sql` Python libraries to manage the Redshift connection. \n",
    "\n",
    "This cell creates a `%sql` element so we can use the connection in other cells in the notebook.\n",
    "\n",
    "-------\n",
    "**Note:** _Please ignore the pink error message that says: \"UserWarning: The psycopg2 wheel package will be renamed from release 2.8\"_   \n",
    "**Look for** 'Connected: ant404@dev' in the 'Out [ ]' section below the warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import simplejson\n",
    "\n",
    "%reload_ext sql\n",
    "%config SqlMagic.displaylimit = 25\n",
    "\n",
    "connect_to_db = 'postgresql+psycopg2://'+username+':'+password+'@'+host_name+':'+port_num+'/'+db_name\n",
    "%sql $connect_to_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Check for existing external `database`/`schema`/`table`\n",
    "These tables should be empty for now because you have not created any external data resources yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM svv_external_databases WHERE databasename = 'logdata';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM svv_external_schemas WHERE schemaname = 'rawlogs';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM svv_external_tables WHERE schemaname = 'rawlogs' ORDER BY schemaname, tablename;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create a new external `schema` and external `database`\n",
    "This SQL references the username your defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Escape autocommit with */END;/* -- */\n",
    "CREATE EXTERNAL SCHEMA IF NOT EXISTS rawlogs\n",
    "FROM DATA CATALOG\n",
    "DATABASE 'logdata'\n",
    "IAM_ROLE 'arn:aws:iam::080945919444:role/mod-27c4c61fae3b42fe-RedshiftClusterRole-1GBP75PRR61RG'\n",
    "CREATE EXTERNAL DATABASE IF NOT EXISTS\n",
    ";\n",
    "SELECT * FROM svv_external_schemas WHERE schemaname = 'rawlogs';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conection Log - Create external table\n",
    "The Connection Log records authentication attempts, connections, and disconnections. It contains the following fields:\n",
    "* `event`: Connection or authentication event.\n",
    "* `recordtime`: Time the event occurred.\n",
    "* `remotehost`: Name or IP address of remote host.\n",
    "* `remoteport`: Port number for remote host.\n",
    "* `pid`: Process ID associated with the statement.\n",
    "* `dbname`: Database name.\n",
    "* `username`: User name.\n",
    "* `authmethod`: Authentication method.\n",
    "* `duration`: Duration of connection in microseconds.\n",
    "\n",
    "* `sslversion`: Secure Sockets Layer (SSL) version.\n",
    "* `sslcipher`: SSL cipher.\n",
    "* `mtu`: Maximum transmission unit (MTU).\n",
    "* `sslcompression`: SSL compression type.\n",
    "* `sslexpansion`: SSL expansion type.\n",
    "* `iamauthguid`: The IAM authentication ID for the CloudTrail request.\n",
    "* `application_name`: The initial or updated name of the application for a session.\n",
    "\n",
    "Use the provided DDL to create an external table for this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "/* -- Escape autocommit with */END;/* -- */\n",
    "DROP TABLE IF EXISTS rawlogs.connectionlog;\n",
    "CREATE EXTERNAL TABLE rawlogs.connectionlog (\n",
    "       event            VARCHAR(64)\n",
    "     , recordtime       VARCHAR(32)\n",
    "     , remotehost       VARCHAR(64)\n",
    "     , remoteport       INTEGER\n",
    "     , pid              INTEGER\n",
    "     , dbname           VARCHAR(64)\n",
    "     , username         VARCHAR(64)\n",
    "     , authmethod       VARCHAR(64)\n",
    "     , duration         BIGINT\n",
    "     , sslversion       VARCHAR(32)\n",
    "     , sslcipher        VARCHAR(32)\n",
    "     , mtu              INTEGER\n",
    "     , sslcompression   VARCHAR(16)\n",
    "     , sslexpansion     VARCHAR(16)\n",
    "     , iamauthguid      VARCHAR(64)\n",
    "     , application_name VARCHAR(64)\n",
    " )\n",
    "PARTITIONED BY (\n",
    "      region VARCHAR(32)\n",
    "    , log_year INT\n",
    "    , log_month INT\n",
    "    , log_day INT\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY '|' \n",
    "LOCATION 's3://ant404-lab-86feeb76/manifests/connectionlog/'\n",
    ";\n",
    "SELECT * FROM svv_external_tables WHERE schemaname = 'rawlogs' AND tablename = 'connectionlog';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conection Log - Add partitions for each day\n",
    "There is no data associated with a partitioned table until at least one partition is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "/* -- Escape autocommit with */END;/* -- */\n",
    "ALTER TABLE rawlogs.connectionlog \n",
    "ADD IF NOT EXISTS\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=1 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_01.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=2 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_02.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=3 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_03.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=4 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_04.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=5 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_05.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=6 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_06.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=7 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_07.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=8 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_08.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=9 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_09.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=10) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_10.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=11) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_11.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=12) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_12.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=13) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_13.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=14) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_14.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=15) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_15.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=16) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_16.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=17) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_17.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=18) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_18.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=19) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_19.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=20) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_20.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=21) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_21.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=22) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_connectionlog_2019_11_22.manifest'\n",
    ";\n",
    "SELECT * FROM svv_external_partitions WHERE schemaname = 'rawlogs' AND tablename = 'connectionlog' ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Conection Log - Verify table works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * \n",
    "FROM rawlogs.connectionlog\n",
    "WHERE log_year = 2019 AND log_month = 11 AND log_day = 9\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _If your query returns no results refer to the **Spectrum Trooubleshooting** section in the START HERE notebook_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. ConnectionLog - Try more queries\n",
    "External tables work just like a regular Redshift local table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- This example finds the max length of each column\n",
    "SELECT MAX(LEN(TRIM(event)))            AS event\n",
    "     , MAX(LEN(TRIM(recordtime)))       AS recordtime\n",
    "     , MAX(LEN(TRIM(remotehost)))       AS remotehost\n",
    "     , MAX(LEN(TRIM(remoteport)))       AS remoteport\n",
    "     , MAX(LEN(TRIM(pid)))              AS pid\n",
    "     , MAX(LEN(TRIM(dbname)))           AS dbname\n",
    "     , MAX(LEN(TRIM(username)))         AS username\n",
    "     , MAX(LEN(TRIM(authmethod)))       AS authmethod\n",
    "     , MAX(LEN(TRIM(duration)))         AS duration\n",
    "     , MAX(LEN(TRIM(sslversion)))       AS sslversion\n",
    "     , MAX(LEN(TRIM(sslcipher)))        AS sslcipher\n",
    "     , MAX(LEN(TRIM(mtu)))              AS mtu\n",
    "     , MAX(LEN(TRIM(sslcompression)))   AS sslcompression\n",
    "     , MAX(LEN(TRIM(sslexpansion)))     AS sslexpansion\n",
    "     , MAX(LEN(TRIM(iamauthguid)))      AS iamauthguid\n",
    "     , MAX(LEN(TRIM(application_name))) AS application_name\n",
    "     , MAX(LEN(TRIM(region)))           AS region\n",
    "     , MAX(LEN(TRIM(log_year)))         AS log_year \n",
    "     , MAX(LEN(TRIM(log_month)))        AS log_month  \n",
    "     , MAX(LEN(TRIM(log_day)))          AS log_day\n",
    "FROM rawlogs.connectionlog \n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. UserActivity Log - Create external table\n",
    "The Activity Log records each query before it is run on the database. It contains the following fields:\n",
    "\n",
    "* `recordtime`: Time the event occurred.\n",
    "* `db`: Database name.\n",
    "* `user`: User name.\n",
    "* `pid`: Process ID associated with the statement.\n",
    "* `userid`: User ID.\n",
    "* `xid`: Transaction ID.\n",
    "* `query`: A prefix of LOG: followed by the text of the query, including newlines.\n",
    "\n",
    "Use the provided DDL to create an external table for this data set.  \n",
    "**Note that this DDL uses a regular expression to define the fields.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Escape autocommit with */END;/* -- */\n",
    "DROP TABLE IF EXISTS rawlogs.useractivitylog;\n",
    "CREATE EXTERNAL TABLE rawlogs.useractivitylog (\n",
    "       quote       CHAR(1)\n",
    "     , recordtime  VARCHAR(32)\n",
    "     , db          VARCHAR(64)\n",
    "     , username    VARCHAR(64)\n",
    "     , pid         BIGINT\n",
    "     , userid      INTEGER\n",
    "     , xid         BIGINT\n",
    "     , query       VARCHAR(MAX)\n",
    " )\n",
    "PARTITIONED BY (\n",
    "      region VARCHAR(32)\n",
    "    , log_year INT\n",
    "    , log_month INT\n",
    "    , log_day INT\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES ('input.regex'='('')(.*) UTC \\\\[ db=(\\\\w+ )user=(\\\\w+) pid=(\\\\d+) userid=(\\\\d+) xid=(\\\\d+) \\\\]'' LOG: (.*)$')\n",
    "LOCATION 's3://ant404-lab-86feeb76/manifests/useractivitylog/'\n",
    ";\n",
    "SELECT * FROM svv_external_tables WHERE schemaname = 'rawlogs' AND tablename = 'useractivitylog';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. UserActivity Log - Add partitions for each day\n",
    "There is no data associated with a partitioned table until at least one partition is added.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Escape autocommit with */END;/* -- */\n",
    "ALTER TABLE rawlogs.useractivitylog \n",
    "ADD IF NOT EXISTS\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=1 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_01.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=2 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_02.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=3 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_03.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=4 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_04.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=5 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_05.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=6 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_06.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=7 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_07.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=8 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_08.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=9 ) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_09.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=10) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_10.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=11) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_11.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=12) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_12.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=13) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_13.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=14) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_14.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=15) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_15.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=16) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_16.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=17) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_17.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=18) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_18.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=19) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_19.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=20) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_20.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=21) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_21.manifest'\n",
    "    PARTITION (region='us-east-1', log_year=2019, log_month=11, log_day=22) LOCATION 's3://ant404-lab-86feeb76/manifests/123456789101_redshift_us-east-1_reporting-cluster_useractivitylog_2019_11_22.manifest'\n",
    ";\n",
    "SELECT * FROM svv_external_partitions WHERE schemaname = 'rawlogs' AND tablename = 'useractivitylog' ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. UserActivity Log - Verify table works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT recordtime\n",
    "     , db \n",
    "     , username \n",
    "     , pid \n",
    "     , userid \n",
    "     , xid \n",
    "     , query \n",
    "FROM rawlogs.useractivitylog\n",
    "WHERE userid > 1 -- # System user is 1\n",
    "  AND log_year = 2019 \n",
    "  AND log_month = 11 \n",
    "ORDER BY username DESC\n",
    "LIMIT 25;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. UserActivity Log - Try more queries on `useractivitylog`\n",
    "External tables work just like a regular Redshift local table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- This example finds the max length of each column\n",
    "SELECT MAX(LEN(TRIM(recordtime))) AS recordtime\n",
    "     , MAX(LEN(TRIM(db        ))) AS db        \n",
    "     , MAX(LEN(TRIM(username  ))) AS username  \n",
    "     , MAX(LEN(TRIM(pid       ))) AS pid       \n",
    "     , MAX(LEN(TRIM(userid    ))) AS userid    \n",
    "     , MAX(LEN(TRIM(xid       ))) AS xid       \n",
    "     , MAX(LEN(TRIM(query     ))) AS query\n",
    "     , MAX(LEN(TRIM(region    ))) AS region\n",
    "     , MAX(LEN(TRIM(log_year  ))) AS log_year \n",
    "     , MAX(LEN(TRIM(log_month ))) AS log_month  \n",
    "     , MAX(LEN(TRIM(log_day   ))) AS log_day\n",
    "FROM rawlogs.useractivitylog \n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. You can also graph your SQL results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql result << \n",
    "SELECT CASE WHEN username = '' THEN '<NONE>' ELSE username END username  \n",
    "     , COUNT(*) log_entries\n",
    "FROM rawlogs.useractivitylog \n",
    "WHERE recordtime <> ''\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Info on Redshift Audit Logs\n",
    "* Redshfit Documentation: [\"Database Audit Logging\"](https://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html)\n",
    "* AWS Documentation: [How do I use logs to track activity in my Amazon Redshift database cluster?](https://aws.amazon.com/premiumsupport/knowledge-center/logs-redshift-database-cluster/)\n",
    "* AWS Blog: [Analyze Database Audit Logs for Security and Compliance Using Amazon Redshift Spectrum](https://aws.amazon.com/blogs/big-data/analyze-database-audit-logs-for-security-and-compliance-using-amazon-redshift-spectrum/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
