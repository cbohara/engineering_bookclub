AWS Reinvent Conference 

##############
MONDAY
##############

##############
12:15pm
ANT204
How Amazon leverages AWS to deliver analytics at enterprise scale
##############

Project Andes
Amazon.com analytics transition from Oracle DW > AWS

ELT = pure SQL statements
(only) had to migrate 1M SQL queries
didn't have to worry about other programming languages in the ecosystem

limited the scope to only structured data + users can query via SQL

EMR allows you to decouple storage + compute = ideal
Redshift = still coupled compute + storaged
however Redshift allows easy querying via SQL

store all data in S3
add layer (catalogue) on top of S3
replicate database like experience

allow users ability to transform/join datasets 

synchronized metadata
built subscription service that would activate ETL based on updates

redshift spectrum = glue + redshift

how to get people off a legacy system on to a new system
standup replica of the warehouse
allow users to manage their own migration strategy timeline

schema conversion tool from AWS
automated query conversion from Oracle to Redshift SQL syntax 

Andes metadata service
any time data changed > synchronize downstream jobs
completion service = track if a job is done
manifests = abstract away file updates to optimize for later reads
audit logging for changes

subscription service
contract = publisher determined governance + SLAs
synchronization = updates data/metadata/schema

synchronizer targets
1. Redshift
2. AWS Glue catalog
fully decoupled storage + compute
3. Redshift spectrum 
launched halfway through migration
turns fully coupled + compute into semi-coupled  
run query against S3 as if running on local Redshift cluster
gained significant new functionality with minimal investment

need to be ready when working in the AWS environment to always update technology

Andes user experience
give full metadata via UI
provide data completness updates
provide schema attributes
enable user to subscribe to a dataset

migration context
Amazon.com does not stop
make sure users have necessary training 

running 2 systems in parallel is super expensive
move users from old system to new system as fast as possible

need to transition 80K users
over-communicate often

Andes has been taking the full analytics workload for Amazon.com for the past 12 months

leverage data migration service (DMS) + schema conversation tool (SCT)


##############
2:30pm
WPT203
We Power Tech - In Diversity + Inclusion, Details Matter
##############

data in diversity + inclusion
ask HR to keep metrics beyond recruitment
keep metrics at a team level

ex: data around how long a population is at a certain level (1 vs 2 vs senior vs staff)
how quickly do they rise up the ranks?

rates of women in CS degrees has decreased(?!)
half of women are likely to leave the field within the first 7 years

bias training is not effective
you can't change a company culture by doing anything once

what can you do to change things?
listen to what other people are staying
apply compassion
hold people accountable 
bias interuptor tool for reviews
https://biasinterrupters.org/toolkits/individualtools/
sponsors - help individuals grow their career

##############
TUESDAY
##############

##############
11:30am
ANT205
What's new with Athena chalktalk
##############

in preview = can query via RDS + DynamoDB

Athena workgroups
more data in data lake > better isolate workload

IAM roles supported
cannot currently limit per specific user - now at the group level
cost allocation tags per workgroup

automated athena queries
can get notified via SNS if what to know if data scans start to creep up

output alternatives to current csv via console
can create user-defined functions now
can currently use SDK + CLI
results of Athena query to Lambda function

JDBC connector to BI tool to avoid timeouts/console issues

query > queue
query shows as running but not actually running
noticing that jobs running slower at the top of the hour - move to middle of the hour

Lake Formation
used to control access permissions per user
even at the column level control, may be row level in the future
facilitates auditing

rumors to automate limiting PII data access 

if underlying data is not columnar based, then even if you only show the user a specific column they are allowed, all data is still scanned
good use case to opt for parquet files moving forward

PrivateLink = private endpoint

question
noticed that queries are slowing down as more and more ad-hoc + automated in a given workgroup 
does each workgroup have it's own queue?

S3 requester = can query s3 in a different account?

in preview = can request to use the new version of presto
better support for geospatial functions

UDF
custom code in SQL queries
Query Federation SDK

ask max increase

https://aws.amazon.com/blogs/big-data/query-any-data-source-with-amazon-athenas-new-federated-query/
SQL queries across data stored in relational, non-relational, object, and custom data sources
Athena executes federated queries using Data Source Connectors that run on AWS Lambda

##############
3:30pm
ANT222
Analytics with Amazon Athena
##############

https://aws.amazon.com/blogs/big-data/query-any-data-source-with-amazon-athenas-new-federated-query/

only available in us-east-1
use specific workgroup when wanting to use new functionality
AmazonAthenaPreviewFunctionality

now can use Athena to query 10 new data sources
build your own UDFs
build your own connectors to custom data sources
apply sagemaker inference as part of your queries
100% open sourcee SDK + connectors

https://github.com/awslabs/aws-athena-query-federation

workshop overview
intro to Athena Federated Query
connect Athena to Amazon Cloudwatch logs
build custom data source
build UDF
use sagemaker

avoid data silos
you can still choose best data store for specific data problem
now query it all from Athena

connectors
- JDBC
Aurora, MySQL, Postgres, Redshift
- Redis  
- CloudWatch Logs + metrics
- CMDB
select * for ec2 instances;

Athena query > lambda function > data sources
built on top of Apache Arrow

Athena will avoid stressing the data source if running read query will hurt your system

1. Connect Athena to Amazon Cloudwatch logs
https://github.com/awslabs/aws-athena-query-federation

https://console.aws.amazon.com/lambda/home?region=us-east-1#/create/app?applicationId=arn:aws:serverlessrepo:us-east-1:292517598671:applications/AthenaCloudwatchConnector
Navigate to Servless Application Repository and search for "athena-federation".
Be sure to check the box to show entries that require custom IAM roles.
Look for entries published by the "Amazon Athena Federation" author.

We used CloudwatchConnector
Provide S3 bucket
AthenaCatalogName
The name you will give to this catalog in Athena. !!It will also be used as the function name!!
Deploy the application

Go to the Athena Console in us-east-1 (N. Virginia) and create a workgroup called "AmazonAthenaPreviewFunctionality", 
any queries run from that workgroup will be able to use Preview features described in this repository.
Run a query "show databses in `lambda:<func_name>`" where <func_name> is the name of the Lambda function you deployed in the previous steps.

2. Create custom connector
https://github.com/awslabs/aws-athena-query-federation/tree/master/athena-example

lesson learned
I am DEFINITELY NOT going to create a custom connection :)
too involved

